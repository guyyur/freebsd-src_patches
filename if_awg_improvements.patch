Index: sys/arm/allwinner/if_awg.c
===================================================================
--- sys/arm/allwinner/if_awg.c	(revision 323952)
+++ sys/arm/allwinner/if_awg.c	(working copy)
@@ -178,6 +178,7 @@ struct awg_rxring {
 	bus_addr_t		desc_ring_paddr;
 	bus_dma_tag_t		buf_tag;
 	struct awg_bufmap	buf_map[RX_DESC_COUNT];
+	bus_dmamap_t		buf_spare_map;
 	u_int			cur;
 };
 
@@ -385,55 +386,52 @@ awg_media_change(if_t ifp)
 	return (error);
 }
 
-static void
-awg_setup_txdesc(struct awg_softc *sc, int index, int flags, bus_addr_t paddr,
-    u_int len)
-{
-	uint32_t status, size;
-
-	if (paddr == 0 || len == 0) {
-		status = 0;
-		size = 0;
-		--sc->tx.queued;
-	} else {
-		status = TX_DESC_CTL;
-		size = flags | len;
-		if ((index & (awg_tx_interval - 1)) == 0)
-			size |= TX_INT_CTL;
-		++sc->tx.queued;
-	}
-
-	sc->tx.desc_ring[index].addr = htole32((uint32_t)paddr);
-	sc->tx.desc_ring[index].size = htole32(size);
-	sc->tx.desc_ring[index].status = htole32(status);
-}
-
 static int
-awg_setup_txbuf(struct awg_softc *sc, int index, struct mbuf **mp)
+awg_encap(struct awg_softc *sc, struct mbuf **mp)
 {
+	bus_dmamap_t map;
 	bus_dma_segment_t segs[TX_MAX_SEGS];
-	int error, nsegs, cur, i, flags;
+	int error, i, nsegs, cur, first, last;
+	uint32_t flags, status;
 	u_int csum_flags;
 	struct mbuf *m;
 
+	cur = first = sc->tx.cur;
+	map = sc->tx.buf_map[first].map;
+
 	m = *mp;
-	error = bus_dmamap_load_mbuf_sg(sc->tx.buf_tag,
-	    sc->tx.buf_map[index].map, m, segs, &nsegs, BUS_DMA_NOWAIT);
+	error = bus_dmamap_load_mbuf_sg(sc->tx.buf_tag, map, m, segs,
+	    &nsegs, BUS_DMA_NOWAIT);
 	if (error == EFBIG) {
 		m = m_collapse(m, M_NOWAIT, TX_MAX_SEGS);
-		if (m == NULL)
-			return (0);
+		if (m == NULL) {
+			m_freem(*mp);
+			*mp = NULL;
+			return (ENOBUFS);
+		}
 		*mp = m;
-		error = bus_dmamap_load_mbuf_sg(sc->tx.buf_tag,
-		    sc->tx.buf_map[index].map, m, segs, &nsegs, BUS_DMA_NOWAIT);
+		error = bus_dmamap_load_mbuf_sg(sc->tx.buf_tag, map, m,
+		    segs, &nsegs, BUS_DMA_NOWAIT);
+		if (error != 0) {
+			m_freem(*mp);
+			*mp = NULL;
+			return (ENOBUFS);
+		}
+	} else if (error != 0)
+		return (error);
+	if (nsegs == 0) {
+		m_freem(*mp);
+		*mp = NULL;
+		return (EIO);
 	}
-	if (error != 0)
-		return (0);
 
-	bus_dmamap_sync(sc->tx.buf_tag, sc->tx.buf_map[index].map,
-	    BUS_DMASYNC_PREWRITE);
+	if (sc->tx.queued + nsegs > TX_DESC_COUNT) {
+		bus_dmamap_unload(sc->tx.buf_tag, map);
+		return (ENOBUFS);
+	}
 
 	flags = TX_FIR_DESC;
+	status = 0;
 	if ((m->m_pkthdr.csum_flags & CSUM_IP) != 0) {
 		if ((m->m_pkthdr.csum_flags & (CSUM_TCP|CSUM_UDP)) != 0)
 			csum_flags = TX_CHECKSUM_CTL_FULL;
@@ -442,20 +440,64 @@ static int
 		flags |= (csum_flags << TX_CHECKSUM_CTL_SHIFT);
 	}
 
-	for (cur = index, i = 0; i < nsegs; i++) {
-		sc->tx.buf_map[cur].mbuf = (i == 0 ? m : NULL);
+	bus_dmamap_sync(sc->tx.buf_tag, map, BUS_DMASYNC_PREWRITE);
+
+	for (i = 0; i < nsegs; i++) {
 		if (i == nsegs - 1)
 			flags |= TX_LAST_DESC;
-		awg_setup_txdesc(sc, cur, flags, segs[i].ds_addr,
-		    segs[i].ds_len);
-		flags &= ~TX_FIR_DESC;
+		if ((cur & (awg_tx_interval - 1)) == 0)
+			flags |= TX_INT_CTL;
+
+	        sc->tx.desc_ring[cur].addr = htole32((uint32_t)segs[i].ds_addr);
+	        sc->tx.desc_ring[cur].size = htole32(flags | segs[i].ds_len);
+	        sc->tx.desc_ring[cur].status = htole32(status);
+
+		flags &= ~(TX_FIR_DESC | TX_INT_CTL);
+
+		/*
+		 * Setting of the valid bit in the first descriptor is
+		 * deferred until the whole chain is fully setup.
+		 */
+		status = TX_DESC_CTL;
+
+		++sc->tx.queued;
 		cur = TX_NEXT(cur);
 	}
 
-	return (nsegs);
+	/*
+	 * the whole mbuf chain has been DMA mapped, fix first descriptor.
+	 */
+	sc->tx.desc_ring[first].status = htole32(TX_DESC_CTL);
+
+	sc->tx.cur = cur;
+
+	/* store mapping and mbuf in the last segment */
+	last = TX_SKIP(cur, TX_DESC_COUNT - 1);
+	sc->tx.buf_map[first].map = sc->tx.buf_map[last].map;
+	sc->tx.buf_map[last].map = map;
+	sc->tx.buf_map[last].mbuf = m;
+
+	return (0);
 }
 
 static void
+awg_clean_txbuf(struct awg_softc *sc, int index)
+{
+	struct awg_bufmap *bmap;
+
+	--sc->tx.queued;
+
+	bmap = &sc->tx.buf_map[index];
+	if (bmap->mbuf != NULL) {
+		bus_dmamap_sync(sc->tx.buf_tag, bmap->map,
+		    BUS_DMASYNC_POSTWRITE);
+		bus_dmamap_unload(sc->tx.buf_tag, bmap->map);
+		m_freem(bmap->mbuf);
+		bmap->mbuf = NULL;
+	}
+}
+
+static void
 awg_setup_rxdesc(struct awg_softc *sc, int index, bus_addr_t paddr)
 {
 	uint32_t status, size;
@@ -465,24 +507,45 @@ awg_setup_rxdesc(struct awg_softc *sc, int index,
 
 	sc->rx.desc_ring[index].addr = htole32((uint32_t)paddr);
 	sc->rx.desc_ring[index].size = htole32(size);
-	sc->rx.desc_ring[index].next =
-	    htole32(sc->rx.desc_ring_paddr + DESC_OFF(RX_NEXT(index)));
 	sc->rx.desc_ring[index].status = htole32(status);
 }
 
+static void
+awg_reuse_rxdesc(struct awg_softc *sc, int index)
+{
+
+	sc->rx.desc_ring[index].status = htole32(RX_DESC_CTL);
+}
+
 static int
-awg_setup_rxbuf(struct awg_softc *sc, int index, struct mbuf *m)
+awg_newbuf_rx(struct awg_softc *sc, int index)
 {
+	struct mbuf *m;
 	bus_dma_segment_t seg;
-	int error, nsegs;
+	bus_dmamap_t map;
+	int nsegs;
 
+	m = m_getcl(M_NOWAIT, MT_DATA, M_PKTHDR);
+	if (m == NULL)
+		return (ENOBUFS);
+
+	m->m_pkthdr.len = m->m_len = m->m_ext.ext_size;
 	m_adj(m, ETHER_ALIGN);
 
-	error = bus_dmamap_load_mbuf_sg(sc->rx.buf_tag,
-	    sc->rx.buf_map[index].map, m, &seg, &nsegs, 0);
-	if (error != 0)
-		return (error);
+	if (bus_dmamap_load_mbuf_sg(sc->rx.buf_tag, sc->rx.buf_spare_map,
+	    m, &seg, &nsegs, BUS_DMA_NOWAIT) != 0) {
+		m_freem(m);
+		return (ENOBUFS);
+	}
 
+	if (sc->rx.buf_map[index].mbuf != NULL) {
+		bus_dmamap_sync(sc->rx.buf_tag, sc->rx.buf_map[index].map,
+		    BUS_DMASYNC_POSTREAD);
+		bus_dmamap_unload(sc->rx.buf_tag, sc->rx.buf_map[index].map);
+	}
+	map = sc->rx.buf_map[index].map;
+	sc->rx.buf_map[index].map = sc->rx.buf_spare_map;
+	sc->rx.buf_spare_map = map;
 	bus_dmamap_sync(sc->rx.buf_tag, sc->rx.buf_map[index].map,
 	    BUS_DMASYNC_PREREAD);
 
@@ -492,18 +555,6 @@ static int
 	return (0);
 }
 
-static struct mbuf *
-awg_alloc_mbufcl(struct awg_softc *sc)
-{
-	struct mbuf *m;
-
-	m = m_getcl(M_NOWAIT, MT_DATA, M_PKTHDR);
-	if (m != NULL)
-		m->m_pkthdr.len = m->m_len = m->m_ext.ext_size;
-
-	return (m);
-}
-
 static void
 awg_start_locked(struct awg_softc *sc)
 {
@@ -510,7 +561,7 @@ awg_start_locked(struct awg_softc *sc)
 	struct mbuf *m;
 	uint32_t val;
 	if_t ifp;
-	int cnt, nsegs;
+	int cnt;
 
 	AWG_ASSERT_LOCKED(sc);
 
@@ -524,22 +575,18 @@ awg_start_locked(struct awg_softc *sc)
 		return;
 
 	for (cnt = 0; ; cnt++) {
-		if (sc->tx.queued >= TX_DESC_COUNT - TX_MAX_SEGS) {
-			if_setdrvflagbits(ifp, IFF_DRV_OACTIVE, 0);
-			break;
-		}
-
 		m = if_dequeue(ifp);
 		if (m == NULL)
 			break;
 
-		nsegs = awg_setup_txbuf(sc, sc->tx.cur, &m);
-		if (nsegs == 0) {
+		if (awg_encap(sc, &m) != 0) {
+			if (m == NULL)
+				break;
 			if_sendq_prepend(ifp, m);
+			if_setdrvflagbits(ifp, IFF_DRV_OACTIVE, 0);
 			break;
 		}
 		if_bpfmtap(ifp, m);
-		sc->tx.cur = TX_SKIP(sc->tx.cur, nsegs);
 	}
 
 	if (cnt != 0) {
@@ -748,6 +795,7 @@ awg_stop(struct awg_softc *sc)
 {
 	if_t ifp;
 	uint32_t val;
+	int i;
 
 	AWG_ASSERT_LOCKED(sc);
 
@@ -782,6 +830,36 @@ awg_stop(struct awg_softc *sc)
 
 	sc->link = 0;
 
+	/* Release any xmit buffers. */
+	for (i = sc->tx.next; sc->tx.queued > 0; i = TX_NEXT(i)) {
+		val = le32toh(sc->tx.desc_ring[i].status);
+		if ((val & TX_DESC_CTL) != 0)
+			break;
+		awg_clean_txbuf(sc, i);
+	}
+	sc->tx.next = i;
+	for (; sc->tx.queued > 0; i = TX_NEXT(i)) {
+		sc->tx.desc_ring[i].status = 0;
+		awg_clean_txbuf(sc, i);
+	}
+	sc->tx.cur = sc->tx.next;
+	bus_dmamap_sync(sc->tx.desc_tag, sc->tx.desc_map,
+	    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);
+
+	/* Setup RX buffers for reuse */
+	bus_dmamap_sync(sc->rx.desc_tag, sc->rx.desc_map,
+	    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);
+
+	for (i = sc->rx.cur; ; i = RX_NEXT(i)) {
+		val = le32toh(sc->rx.desc_ring[i].status);
+		if ((val & RX_DESC_CTL) != 0)
+			break;
+		awg_reuse_rxdesc(sc, i);
+	}
+	sc->rx.cur = i;
+	bus_dmamap_sync(sc->rx.desc_tag, sc->rx.desc_map,
+	    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);
+
 	if_setdrvflagbits(ifp, 0, IFF_DRV_RUNNING | IFF_DRV_OACTIVE);
 }
 
@@ -789,7 +867,7 @@ static int
 awg_rxintr(struct awg_softc *sc)
 {
 	if_t ifp;
-	struct mbuf *m, *m0, *mh, *mt;
+	struct mbuf *m, *mh, *mt;
 	int error, index, len, cnt, npkt;
 	uint32_t status;
 
@@ -806,61 +884,62 @@ awg_rxintr(struct awg_softc *sc)
 		if ((status & RX_DESC_CTL) != 0)
 			break;
 
-		bus_dmamap_sync(sc->rx.buf_tag, sc->rx.buf_map[index].map,
-		    BUS_DMASYNC_POSTREAD);
-		bus_dmamap_unload(sc->rx.buf_tag, sc->rx.buf_map[index].map);
-
 		len = (status & RX_FRM_LEN) >> RX_FRM_LEN_SHIFT;
-		if (len != 0) {
-			m = sc->rx.buf_map[index].mbuf;
-			m->m_pkthdr.rcvif = ifp;
-			m->m_pkthdr.len = len;
-			m->m_len = len;
-			if_inc_counter(ifp, IFCOUNTER_IPACKETS, 1);
 
-			if ((if_getcapenable(ifp) & IFCAP_RXCSUM) != 0 &&
-			    (status & RX_FRM_TYPE) != 0) {
-				m->m_pkthdr.csum_flags = CSUM_IP_CHECKED;
-				if ((status & RX_HEADER_ERR) == 0)
-					m->m_pkthdr.csum_flags |= CSUM_IP_VALID;
-				if ((status & RX_PAYLOAD_ERR) == 0) {
-					m->m_pkthdr.csum_flags |=
-					    CSUM_DATA_VALID | CSUM_PSEUDO_HDR;
-					m->m_pkthdr.csum_data = 0xffff;
-				}
-			}
+		if (len == 0) {
+			if ((status & (RX_NO_ENOUGH_BUF_ERR | RX_OVERFLOW_ERR)) != 0)
+				if_inc_counter(ifp, IFCOUNTER_IERRORS, 1);
+			awg_reuse_rxdesc(sc, index);
+			continue;
+		}
 
-			m->m_nextpkt = NULL;
-			if (mh == NULL)
-				mh = m;
-			else
-				mt->m_nextpkt = m;
-			mt = m;
-			++cnt;
-			++npkt;
+		m = sc->rx.buf_map[index].mbuf;
 
-			if (cnt == awg_rx_batch) {
-				AWG_UNLOCK(sc);
-				if_input(ifp, mh);
-				AWG_LOCK(sc);
-				mh = mt = NULL;
-				cnt = 0;
+		error = awg_newbuf_rx(sc, index);
+		if (error != 0) {
+			if_inc_counter(ifp, IFCOUNTER_IQDROPS, 1);
+			awg_reuse_rxdesc(sc, index);
+			continue;
+		}
+
+		m->m_pkthdr.rcvif = ifp;
+		m->m_pkthdr.len = len;
+		m->m_len = len;
+		if_inc_counter(ifp, IFCOUNTER_IPACKETS, 1);
+
+		if ((if_getcapenable(ifp) & IFCAP_RXCSUM) != 0 &&
+		    (status & RX_FRM_TYPE) != 0) {
+			m->m_pkthdr.csum_flags = CSUM_IP_CHECKED;
+			if ((status & RX_HEADER_ERR) == 0)
+				m->m_pkthdr.csum_flags |= CSUM_IP_VALID;
+			if ((status & RX_PAYLOAD_ERR) == 0) {
+				m->m_pkthdr.csum_flags |=
+				    CSUM_DATA_VALID | CSUM_PSEUDO_HDR;
+				m->m_pkthdr.csum_data = 0xffff;
 			}
-			
 		}
 
-		if ((m0 = awg_alloc_mbufcl(sc)) != NULL) {
-			error = awg_setup_rxbuf(sc, index, m0);
-			if (error != 0) {
-				/* XXX hole in RX ring */
-			}
-		} else
-			if_inc_counter(ifp, IFCOUNTER_IQDROPS, 1);
+		m->m_nextpkt = NULL;
+		if (mh == NULL)
+			mh = m;
+		else
+			mt->m_nextpkt = m;
+		mt = m;
+		++cnt;
+		++npkt;
+
+		if (cnt == awg_rx_batch) {
+			AWG_UNLOCK(sc);
+			if_input(ifp, mh);
+			AWG_LOCK(sc);
+			mh = mt = NULL;
+			cnt = 0;
+		}
 	}
 
 	if (index != sc->rx.cur) {
 		bus_dmamap_sync(sc->rx.desc_tag, sc->rx.desc_map,
-		    BUS_DMASYNC_PREWRITE);
+		    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);
 	}
 
 	if (mh != NULL) {
@@ -875,13 +954,12 @@ awg_rxintr(struct awg_softc *sc)
 }
 
 static void
-awg_txintr(struct awg_softc *sc)
+awg_txeof(struct awg_softc *sc)
 {
-	struct awg_bufmap *bmap;
 	struct emac_desc *desc;
 	uint32_t status;
 	if_t ifp;
-	int i;
+	int i, prog;
 
 	AWG_ASSERT_LOCKED(sc);
 
@@ -889,28 +967,28 @@ static void
 	    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);
 
 	ifp = sc->ifp;
+
+	prog = 0;
 	for (i = sc->tx.next; sc->tx.queued > 0; i = TX_NEXT(i)) {
 		desc = &sc->tx.desc_ring[i];
 		status = le32toh(desc->status);
 		if ((status & TX_DESC_CTL) != 0)
 			break;
-		bmap = &sc->tx.buf_map[i];
-		if (bmap->mbuf != NULL) {
-			bus_dmamap_sync(sc->tx.buf_tag, bmap->map,
-			    BUS_DMASYNC_POSTWRITE);
-			bus_dmamap_unload(sc->tx.buf_tag, bmap->map);
-			m_freem(bmap->mbuf);
-			bmap->mbuf = NULL;
+
+		prog++;
+		awg_clean_txbuf(sc, i);
+		if ((status & (TX_HEADER_ERR | TX_PAYLOAD_ERR)) != 0) {
+			if_inc_counter(ifp, IFCOUNTER_OERRORS, 1);
 		}
-		awg_setup_txdesc(sc, i, 0, 0, 0);
+		else {
+			if_inc_counter(ifp, IFCOUNTER_OPACKETS, 1);
+		}
+	}
+
+	if (prog > 0) {
+		sc->tx.next = i;
 		if_setdrvflagbits(ifp, 0, IFF_DRV_OACTIVE);
-		if_inc_counter(ifp, IFCOUNTER_OPACKETS, 1);
 	}
-
-	sc->tx.next = i;
-
-	bus_dmamap_sync(sc->tx.desc_tag, sc->tx.desc_map,
-	    BUS_DMASYNC_PREWRITE);
 }
 
 static void
@@ -928,8 +1006,10 @@ awg_intr(void *arg)
 	if (val & RX_INT)
 		awg_rxintr(sc);
 
-	if (val & (TX_INT|TX_BUF_UA_INT)) {
-		awg_txintr(sc);
+	if (val & TX_INT)
+		awg_txeof(sc);
+
+	if (val & (TX_INT | TX_BUF_UA_INT)) {
 		if (!if_sendq_empty(sc->ifp))
 			awg_start_locked(sc);
 	}
@@ -956,7 +1036,7 @@ awg_poll(if_t ifp, enum poll_cmd cmd, int count)
 	}
 
 	rx_npkts = awg_rxintr(sc);
-	awg_txintr(sc);
+	awg_txeof(sc);
 	if (!if_sendq_empty(ifp))
 		awg_start_locked(sc);
 
@@ -1041,10 +1121,10 @@ awg_ioctl(if_t ifp, u_long cmd, caddr_t data)
 			if_togglecapenable(ifp, IFCAP_RXCSUM);
 		if (mask & IFCAP_TXCSUM)
 			if_togglecapenable(ifp, IFCAP_TXCSUM);
-		if ((if_getcapenable(ifp) & (IFCAP_RXCSUM|IFCAP_TXCSUM)) != 0)
-			if_sethwassistbits(ifp, CSUM_IP, 0);
+		if ((if_getcapenable(ifp) & IFCAP_TXCSUM) != 0)
+			if_sethwassistbits(ifp, CSUM_IP | CSUM_UDP | CSUM_TCP, 0);
 		else
-			if_sethwassistbits(ifp, 0, CSUM_IP);
+			if_sethwassistbits(ifp, 0, CSUM_IP | CSUM_UDP | CSUM_TCP);
 		break;
 	default:
 		error = ether_ioctl(ifp, cmd, data);
@@ -1448,7 +1528,6 @@ static int
 awg_setup_dma(device_t dev)
 {
 	struct awg_softc *sc;
-	struct mbuf *m;
 	int error, i;
 
 	sc = device_get_softc(dev);
@@ -1505,7 +1584,7 @@ awg_setup_dma(device_t dev)
 		return (error);
 	}
 
-	sc->tx.queued = TX_DESC_COUNT;
+	sc->tx.queued = 0;
 	for (i = 0; i < TX_DESC_COUNT; i++) {
 		error = bus_dmamap_create(sc->tx.buf_tag, 0,
 		    &sc->tx.buf_map[i].map);
@@ -1513,7 +1592,6 @@ awg_setup_dma(device_t dev)
 			device_printf(dev, "cannot create TX buffer map\n");
 			return (error);
 		}
-		awg_setup_txdesc(sc, i, 0, 0, 0);
 	}
 
 	/* Setup RX ring */
@@ -1564,7 +1642,17 @@ awg_setup_dma(device_t dev)
 		return (error);
 	}
 
+	error = bus_dmamap_create(sc->rx.buf_tag, 0, &sc->rx.buf_spare_map);
+	if (error != 0) {
+		device_printf(dev,
+		    "cannot create RX buffer spare map\n");
+		return (error);
+	}
+
 	for (i = 0; i < RX_DESC_COUNT; i++) {
+		sc->rx.desc_ring[i].next =
+		    htole32(sc->rx.desc_ring_paddr + DESC_OFF(RX_NEXT(i)));
+
 		error = bus_dmamap_create(sc->rx.buf_tag, 0,
 		    &sc->rx.buf_map[i].map);
 		if (error != 0) {
@@ -1571,11 +1659,8 @@ awg_setup_dma(device_t dev)
 			device_printf(dev, "cannot create RX buffer map\n");
 			return (error);
 		}
-		if ((m = awg_alloc_mbufcl(sc)) == NULL) {
-			device_printf(dev, "cannot allocate RX mbuf\n");
-			return (ENOMEM);
-		}
-		error = awg_setup_rxbuf(sc, i, m);
+		sc->rx.buf_map[i].mbuf = NULL;
+		error = awg_newbuf_rx(sc, i);
 		if (error != 0) {
 			device_printf(dev, "cannot create RX buffer\n");
 			return (error);
Index: sys/arm/allwinner/if_awgreg.h
===================================================================
--- sys/arm/allwinner/if_awgreg.h	(revision 323952)
+++ sys/arm/allwinner/if_awgreg.h	(working copy)
@@ -115,9 +115,9 @@
 #define	EMAC_MII_DATA		0x4c
 #define	EMAC_ADDR_HIGH(n)	(0x50 + (n) * 8)
 #define	EMAC_ADDR_LOW(n)	(0x54 + (n) * 8)
-#define	EMAC_TX_DMA_STA		0x80
-#define	EMAC_TX_DMA_CUR_DESC	0x84
-#define	EMAC_TX_DMA_CUR_BUF	0x88
+#define	EMAC_TX_DMA_STA		0xb0
+#define	EMAC_TX_DMA_CUR_DESC	0xb4
+#define	EMAC_TX_DMA_CUR_BUF	0xb8
 #define	EMAC_RX_DMA_STA		0xc0
 #define	EMAC_RX_DMA_CUR_DESC	0xc4
 #define	EMAC_RX_DMA_CUR_BUF	0xc8
