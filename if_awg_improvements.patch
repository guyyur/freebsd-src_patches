Index: sys/arm/allwinner/if_awg.c
===================================================================
--- sys/arm/allwinner/if_awg.c	(revision 323952)
+++ sys/arm/allwinner/if_awg.c	(working copy)
@@ -178,6 +178,7 @@ struct awg_rxring {
 	bus_addr_t		desc_ring_paddr;
 	bus_dma_tag_t		buf_tag;
 	struct awg_bufmap	buf_map[RX_DESC_COUNT];
+	bus_dmamap_t		buf_spare_map;
 	u_int			cur;
 };
 
@@ -409,29 +410,48 @@ awg_setup_txdesc(struct awg_softc *sc, int index,
 }
 
 static int
-awg_setup_txbuf(struct awg_softc *sc, int index, struct mbuf **mp)
+awg_setup_txbuf(struct awg_softc *sc, struct mbuf **mp)
 {
+	bus_dmamap_t map;
 	bus_dma_segment_t segs[TX_MAX_SEGS];
-	int error, nsegs, cur, i, flags;
+	int error, i, nsegs, cur, si, flags;
 	u_int csum_flags;
 	struct mbuf *m;
 
+	cur = si = sc->tx.cur;
+	map = sc->tx.buf_map[cur].map;
+
 	m = *mp;
-	error = bus_dmamap_load_mbuf_sg(sc->tx.buf_tag,
-	    sc->tx.buf_map[index].map, m, segs, &nsegs, BUS_DMA_NOWAIT);
+	error = bus_dmamap_load_mbuf_sg(sc->tx.buf_tag, map, m, segs,
+	    &nsegs, BUS_DMA_NOWAIT);
 	if (error == EFBIG) {
 		m = m_collapse(m, M_NOWAIT, TX_MAX_SEGS);
-		if (m == NULL)
-			return (0);
+		if (m == NULL) {
+			m_freem(*mp);
+			*mp = NULL;
+			return (ENOBUFS);
+		}
 		*mp = m;
-		error = bus_dmamap_load_mbuf_sg(sc->tx.buf_tag,
-		    sc->tx.buf_map[index].map, m, segs, &nsegs, BUS_DMA_NOWAIT);
+		error = bus_dmamap_load_mbuf_sg(sc->tx.buf_tag, map, m,
+		    segs, &nsegs, BUS_DMA_NOWAIT);
+		if (error != 0) {
+			m_freem(*mp);
+			*mp = NULL;
+			return (ENOBUFS);
+		}
+	} else if (error != 0) {
+		return (error);
 	}
-	if (error != 0)
-		return (0);
+	if (nsegs == 0) {
+		m_freem(*mp);
+		*mp = NULL;
+		return (EIO);
+	}
 
-	bus_dmamap_sync(sc->tx.buf_tag, sc->tx.buf_map[index].map,
-	    BUS_DMASYNC_PREWRITE);
+	if (sc->tx.queued + nsegs >= TX_DESC_COUNT - 2) {
+		bus_dmamap_unload(sc->tx.buf_tag, map);
+		return (ENOBUFS);
+	}
 
 	flags = TX_FIR_DESC;
 	if ((m->m_pkthdr.csum_flags & CSUM_IP) != 0) {
@@ -442,8 +462,7 @@ static int
 		flags |= (csum_flags << TX_CHECKSUM_CTL_SHIFT);
 	}
 
-	for (cur = index, i = 0; i < nsegs; i++) {
-		sc->tx.buf_map[cur].mbuf = (i == 0 ? m : NULL);
+	for (i = 0; i < nsegs; i++) {
 		if (i == nsegs - 1)
 			flags |= TX_LAST_DESC;
 		awg_setup_txdesc(sc, cur, flags, segs[i].ds_addr,
@@ -452,7 +471,15 @@ static int
 		cur = TX_NEXT(cur);
 	}
 
-	return (nsegs);
+	sc->tx.cur = cur;
+	cur = TX_SKIP(cur, TX_DESC_COUNT - 1);
+	sc->tx.buf_map[si].map = sc->tx.buf_map[cur].map;
+	sc->tx.buf_map[cur].map = map;
+	sc->tx.buf_map[cur].mbuf = m;
+
+	bus_dmamap_sync(sc->tx.buf_tag, map, BUS_DMASYNC_PREWRITE);
+
+	return (0);
 }
 
 static void
@@ -465,24 +492,45 @@ awg_setup_rxdesc(struct awg_softc *sc, int index,
 
 	sc->rx.desc_ring[index].addr = htole32((uint32_t)paddr);
 	sc->rx.desc_ring[index].size = htole32(size);
-	sc->rx.desc_ring[index].next =
-	    htole32(sc->rx.desc_ring_paddr + DESC_OFF(RX_NEXT(index)));
 	sc->rx.desc_ring[index].status = htole32(status);
 }
 
+static void
+awg_reuse_rxdesc(struct awg_softc *sc, int index)
+{
+
+	awg_setup_rxdesc(sc, index, le32toh(sc->rx.desc_ring[index].addr));
+}
+
 static int
-awg_setup_rxbuf(struct awg_softc *sc, int index, struct mbuf *m)
+awg_newbuf_rx(struct awg_softc *sc, int index)
 {
+	struct mbuf *m;
 	bus_dma_segment_t seg;
-	int error, nsegs;
+	bus_dmamap_t map;
+	int nsegs;
 
+	m = m_getcl(M_NOWAIT, MT_DATA, M_PKTHDR);
+	if (m == NULL)
+		return (ENOBUFS);
+
+	m->m_pkthdr.len = m->m_len = m->m_ext.ext_size;
 	m_adj(m, ETHER_ALIGN);
 
-	error = bus_dmamap_load_mbuf_sg(sc->rx.buf_tag,
-	    sc->rx.buf_map[index].map, m, &seg, &nsegs, 0);
-	if (error != 0)
-		return (error);
+	if (bus_dmamap_load_mbuf_sg(sc->rx.buf_tag, sc->rx.buf_spare_map,
+	    m, &seg, &nsegs, BUS_DMA_NOWAIT) != 0) {
+		m_freem(m);
+		return (ENOBUFS);
+	}
 
+	if (sc->rx.buf_map[index].mbuf != NULL) {
+		bus_dmamap_sync(sc->rx.buf_tag, sc->rx.buf_map[index].map,
+		    BUS_DMASYNC_POSTREAD);
+		bus_dmamap_unload(sc->rx.buf_tag, sc->rx.buf_map[index].map);
+	}
+	map = sc->rx.buf_map[index].map;
+	sc->rx.buf_map[index].map = sc->rx.buf_spare_map;
+	sc->rx.buf_spare_map = map;
 	bus_dmamap_sync(sc->rx.buf_tag, sc->rx.buf_map[index].map,
 	    BUS_DMASYNC_PREREAD);
 
@@ -492,18 +540,6 @@ static int
 	return (0);
 }
 
-static struct mbuf *
-awg_alloc_mbufcl(struct awg_softc *sc)
-{
-	struct mbuf *m;
-
-	m = m_getcl(M_NOWAIT, MT_DATA, M_PKTHDR);
-	if (m != NULL)
-		m->m_pkthdr.len = m->m_len = m->m_ext.ext_size;
-
-	return (m);
-}
-
 static void
 awg_start_locked(struct awg_softc *sc)
 {
@@ -510,7 +546,7 @@ awg_start_locked(struct awg_softc *sc)
 	struct mbuf *m;
 	uint32_t val;
 	if_t ifp;
-	int cnt, nsegs;
+	int cnt;
 
 	AWG_ASSERT_LOCKED(sc);
 
@@ -524,22 +560,18 @@ awg_start_locked(struct awg_softc *sc)
 		return;
 
 	for (cnt = 0; ; cnt++) {
-		if (sc->tx.queued >= TX_DESC_COUNT - TX_MAX_SEGS) {
-			if_setdrvflagbits(ifp, IFF_DRV_OACTIVE, 0);
-			break;
-		}
-
 		m = if_dequeue(ifp);
 		if (m == NULL)
 			break;
 
-		nsegs = awg_setup_txbuf(sc, sc->tx.cur, &m);
-		if (nsegs == 0) {
+		if (awg_setup_txbuf(sc, &m) != 0) {
+			if (m == NULL)
+				break;
 			if_sendq_prepend(ifp, m);
+			if_setdrvflagbits(ifp, IFF_DRV_OACTIVE, 0);
 			break;
 		}
 		if_bpfmtap(ifp, m);
-		sc->tx.cur = TX_SKIP(sc->tx.cur, nsegs);
 	}
 
 	if (cnt != 0) {
@@ -789,7 +821,7 @@ static int
 awg_rxintr(struct awg_softc *sc)
 {
 	if_t ifp;
-	struct mbuf *m, *m0, *mh, *mt;
+	struct mbuf *m, *mh, *mt;
 	int error, index, len, cnt, npkt;
 	uint32_t status;
 
@@ -806,61 +838,62 @@ awg_rxintr(struct awg_softc *sc)
 		if ((status & RX_DESC_CTL) != 0)
 			break;
 
-		bus_dmamap_sync(sc->rx.buf_tag, sc->rx.buf_map[index].map,
-		    BUS_DMASYNC_POSTREAD);
-		bus_dmamap_unload(sc->rx.buf_tag, sc->rx.buf_map[index].map);
-
 		len = (status & RX_FRM_LEN) >> RX_FRM_LEN_SHIFT;
-		if (len != 0) {
-			m = sc->rx.buf_map[index].mbuf;
-			m->m_pkthdr.rcvif = ifp;
-			m->m_pkthdr.len = len;
-			m->m_len = len;
-			if_inc_counter(ifp, IFCOUNTER_IPACKETS, 1);
 
-			if ((if_getcapenable(ifp) & IFCAP_RXCSUM) != 0 &&
-			    (status & RX_FRM_TYPE) != 0) {
-				m->m_pkthdr.csum_flags = CSUM_IP_CHECKED;
-				if ((status & RX_HEADER_ERR) == 0)
-					m->m_pkthdr.csum_flags |= CSUM_IP_VALID;
-				if ((status & RX_PAYLOAD_ERR) == 0) {
-					m->m_pkthdr.csum_flags |=
-					    CSUM_DATA_VALID | CSUM_PSEUDO_HDR;
-					m->m_pkthdr.csum_data = 0xffff;
-				}
-			}
+		if (len == 0) {
+			if (status & (RX_NO_ENOUGH_BUF_ERR | RX_OVERFLOW_ERR))
+				if_inc_counter(ifp, IFCOUNTER_IERRORS, 1);
+			awg_reuse_rxdesc(sc, index);
+			continue;
+		}
 
-			m->m_nextpkt = NULL;
-			if (mh == NULL)
-				mh = m;
-			else
-				mt->m_nextpkt = m;
-			mt = m;
-			++cnt;
-			++npkt;
+		m = sc->rx.buf_map[index].mbuf;
 
-			if (cnt == awg_rx_batch) {
-				AWG_UNLOCK(sc);
-				if_input(ifp, mh);
-				AWG_LOCK(sc);
-				mh = mt = NULL;
-				cnt = 0;
+		error = awg_newbuf_rx(sc, index);
+		if (error != 0) {
+			if_inc_counter(ifp, IFCOUNTER_IQDROPS, 1);
+			awg_reuse_rxdesc(sc, index);
+			continue;
+		}
+
+		m->m_pkthdr.rcvif = ifp;
+		m->m_pkthdr.len = len;
+		m->m_len = len;
+		if_inc_counter(ifp, IFCOUNTER_IPACKETS, 1);
+
+		if ((if_getcapenable(ifp) & IFCAP_RXCSUM) != 0 &&
+		    (status & RX_FRM_TYPE) != 0) {
+			m->m_pkthdr.csum_flags = CSUM_IP_CHECKED;
+			if ((status & RX_HEADER_ERR) == 0)
+				m->m_pkthdr.csum_flags |= CSUM_IP_VALID;
+			if ((status & RX_PAYLOAD_ERR) == 0) {
+				m->m_pkthdr.csum_flags |=
+				    CSUM_DATA_VALID | CSUM_PSEUDO_HDR;
+				m->m_pkthdr.csum_data = 0xffff;
 			}
-			
 		}
 
-		if ((m0 = awg_alloc_mbufcl(sc)) != NULL) {
-			error = awg_setup_rxbuf(sc, index, m0);
-			if (error != 0) {
-				/* XXX hole in RX ring */
-			}
-		} else
-			if_inc_counter(ifp, IFCOUNTER_IQDROPS, 1);
+		m->m_nextpkt = NULL;
+		if (mh == NULL)
+			mh = m;
+		else
+			mt->m_nextpkt = m;
+		mt = m;
+		++cnt;
+		++npkt;
+
+		if (cnt == awg_rx_batch) {
+			AWG_UNLOCK(sc);
+			if_input(ifp, mh);
+			AWG_LOCK(sc);
+			mh = mt = NULL;
+			cnt = 0;
+		}
 	}
 
 	if (index != sc->rx.cur) {
 		bus_dmamap_sync(sc->rx.desc_tag, sc->rx.desc_map,
-		    BUS_DMASYNC_PREWRITE);
+		    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);
 	}
 
 	if (mh != NULL) {
@@ -1448,7 +1481,6 @@ static int
 awg_setup_dma(device_t dev)
 {
 	struct awg_softc *sc;
-	struct mbuf *m;
 	int error, i;
 
 	sc = device_get_softc(dev);
@@ -1564,7 +1596,17 @@ awg_setup_dma(device_t dev)
 		return (error);
 	}
 
+        error = bus_dmamap_create(sc->rx.buf_tag, 0, &sc->rx.buf_spare_map);
+        if (error != 0) {
+                device_printf(dev,
+                    "cannot create RX buffer spare map\n");
+                return (error);
+        }
+
 	for (i = 0; i < RX_DESC_COUNT; i++) {
+		sc->rx.desc_ring[i].next =
+		    htole32(sc->rx.desc_ring_paddr + DESC_OFF(RX_NEXT(i)));
+
 		error = bus_dmamap_create(sc->rx.buf_tag, 0,
 		    &sc->rx.buf_map[i].map);
 		if (error != 0) {
@@ -1571,11 +1613,8 @@ awg_setup_dma(device_t dev)
 			device_printf(dev, "cannot create RX buffer map\n");
 			return (error);
 		}
-		if ((m = awg_alloc_mbufcl(sc)) == NULL) {
-			device_printf(dev, "cannot allocate RX mbuf\n");
-			return (ENOMEM);
-		}
-		error = awg_setup_rxbuf(sc, i, m);
+		sc->rx.buf_map[i].mbuf = NULL;
+		error = awg_newbuf_rx(sc, i);
 		if (error != 0) {
 			device_printf(dev, "cannot create RX buffer\n");
 			return (error);
